{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental DFA Decomposition: Per-Step Work Scaling\n",
    "\n",
    "This notebook demonstrates that the incremental `TruncatedIncrementalDFADecomp`\n",
    "does per-step work proportional to the **change** in the DFA graph (dirty + border\n",
    "states), not the total DFA size or target string length.\n",
    "\n",
    "We run several FSTs through long `>>` chains and show:\n",
    "1. **Total DFA states** grows linearly with target length.\n",
    "2. **States expanded per step** stays constant (after initial transient).\n",
    "3. **Wall-clock time per step** stays constant, while from-scratch construction grows.\n",
    "\n",
    "### How the measurement works\n",
    "\n",
    "Each `TruncatedIncrementalDFADecomp` instance records `_stats` with:\n",
    "- `n_dirty` / `n_border`: states invalidated by the target extension\n",
    "- `n_expanded`: states whose arcs were (re-)computed in the BFS\n",
    "- `n_arcs`: arcs added during expansion\n",
    "- `total_dfa_states`: cumulative DFA states after this step\n",
    "- `n_frontier`: states that will be dirty on the *next* extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transduction import examples\n",
    "from transduction.dfa_decomp_incremental_truncated import TruncatedIncrementalDFADecomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_incremental_stats(fst, target_string):\n",
    "    \"\"\"Run incremental >> chain, collecting per-step stats and timing.\"\"\"\n",
    "    records = []\n",
    "    s = TruncatedIncrementalDFADecomp(fst, '')\n",
    "    for i, y in enumerate(target_string):\n",
    "        t0 = time.perf_counter()\n",
    "        s = s >> y\n",
    "        dt = time.perf_counter() - t0\n",
    "        rec = dict(s._stats)\n",
    "        rec['step'] = i + 1\n",
    "        rec['time_s'] = dt\n",
    "        records.append(rec)\n",
    "    return records\n",
    "\n",
    "\n",
    "def collect_from_scratch_stats(fst, target_string):\n",
    "    \"\"\"Build from scratch for each target prefix, collecting timing.\"\"\"\n",
    "    records = []\n",
    "    for i in range(1, len(target_string) + 1):\n",
    "        prefix = target_string[:i]\n",
    "        t0 = time.perf_counter()\n",
    "        s = TruncatedIncrementalDFADecomp(fst, prefix)\n",
    "        dt = time.perf_counter() - t0\n",
    "        rec = dict(s._stats)\n",
    "        rec['step'] = i\n",
    "        rec['time_s'] = dt\n",
    "        records.append(rec)\n",
    "    return records\n",
    "\n",
    "\n",
    "def rolling_median(data, window=7):\n",
    "    out = []\n",
    "    for i in range(len(data)):\n",
    "        lo = max(0, i - window // 2)\n",
    "        hi = min(len(data), i + window // 2 + 1)\n",
    "        out.append(np.median(data[lo:hi]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "\n",
    "benchmarks = [\n",
    "    ('triplets of doom', examples.triplets_of_doom(), 'a' * N),\n",
    "    ('3-tuples of doom', examples.doom(set('abc'), 3), ('abc' * 80)[:N]),\n",
    "    ('lookahead',        examples.lookahead(),         ('ab' * 120)[:N]),\n",
    "    ('duplicate',        examples.duplicate(set('12345')), ('1122334455' * 25)[:N]),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for name, fst, target in benchmarks:\n",
    "    incr = collect_incremental_stats(fst, target)\n",
    "    scratch = collect_from_scratch_stats(fst, target)\n",
    "    results[name] = {'incremental': incr, 'from_scratch': scratch}\n",
    "    print(f'{name}: {len(target)} steps, final DFA size = {incr[-1][\"total_dfa_states\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total DFA states vs. states expanded per step\n",
    "\n",
    "The left axis (blue) shows the total DFA size growing linearly with target length.\n",
    "The right axis (red) shows the per-step work (states expanded) staying **flat**.\n",
    "\n",
    "This is the main claim: per-step cost is O(|change|), not O(|full DFA|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Total DFA size (blue, left axis) vs. states expanded per step (red, right axis)', fontsize=13)\n",
    "\n",
    "for ax, name in zip(axes.flat, results):\n",
    "    incr = results[name]['incremental']\n",
    "    steps = [r['step'] for r in incr]\n",
    "    total = [r['total_dfa_states'] for r in incr]\n",
    "    expanded = [r['n_expanded'] for r in incr]\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax.plot(steps, total, 'b-', linewidth=1.5, label='total DFA states')\n",
    "    ax2.plot(steps, expanded, 'r-', linewidth=1.5, label='states expanded')\n",
    "\n",
    "    ax.set_xlabel('target length')\n",
    "    ax.set_ylabel('total DFA states', color='b')\n",
    "    ax2.set_ylabel('states expanded (per step)', color='r')\n",
    "    ax.set_title(name)\n",
    "    ax.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    ax2.set_ylim(bottom=0, top=max(expanded) * 2.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('reports/incremental_scaling_states.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown: dirty, border, expanded, frontier, arcs\n",
    "\n",
    "All five per-step quantities stabilize after an initial transient (steps 1-2)\n",
    "and remain constant regardless of how large the DFA grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Per-step work breakdown (all quantities stay bounded)', fontsize=13)\n",
    "\n",
    "for ax, name in zip(axes.flat, results):\n",
    "    incr = results[name]['incremental']\n",
    "    steps = [r['step'] for r in incr]\n",
    "\n",
    "    for key, color, label in [\n",
    "        ('n_dirty',    'tab:red',    'dirty'),\n",
    "        ('n_border',   'tab:orange', 'border'),\n",
    "        ('n_expanded', 'tab:blue',   'expanded'),\n",
    "        ('n_frontier', 'tab:green',  'frontier'),\n",
    "        ('n_arcs',     'tab:purple', 'arcs added'),\n",
    "    ]:\n",
    "        ax.plot(steps, [r[key] for r in incr], color=color, label=label, linewidth=1.2)\n",
    "\n",
    "    ax.set_xlabel('target length')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_title(name)\n",
    "    ax.legend(fontsize=7, loc='upper right')\n",
    "    ax.set_ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('reports/incremental_scaling_breakdown.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wall-clock time: incremental vs. from-scratch\n",
    "\n",
    "From-scratch rebuilds the full DFA each step (O(|total states|) BFS).\n",
    "Incremental `>>` only re-expands dirty+border states (O(|change|)).\n",
    "\n",
    "Rolling median smooths sub-millisecond timer noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Wall-clock time per step: incremental (blue) vs from-scratch (gray)\\n(rolling median, window=7)', fontsize=13)\n",
    "\n",
    "for ax, name in zip(axes.flat, results):\n",
    "    incr = results[name]['incremental']\n",
    "    scratch = results[name]['from_scratch']\n",
    "    steps_i = [r['step'] for r in incr]\n",
    "    steps_s = [r['step'] for r in scratch]\n",
    "    t_incr = [r['time_s'] * 1000 for r in incr]\n",
    "    t_scratch = [r['time_s'] * 1000 for r in scratch]\n",
    "\n",
    "    ax.plot(steps_s, rolling_median(t_scratch),\n",
    "            color='gray', linewidth=1.5, alpha=0.8, label='from scratch')\n",
    "    ax.plot(steps_i, rolling_median(t_incr),\n",
    "            color='tab:blue', linewidth=1.5, label='incremental >>')\n",
    "\n",
    "    ax.set_xlabel('target length')\n",
    "    ax.set_ylabel('time (ms)')\n",
    "    ax.set_title(name)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('reports/incremental_scaling_time.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table\n",
    "\n",
    "Steady-state per-step metrics (median over steps 6+) vs final DFA size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"FST\":25s} {\"final states\":>12s} {\"expanded/step\":>14s} {\"dirty/step\":>11s} {\"border/step\":>12s} {\"incr (ms)\":>10s} {\"scratch (ms)\":>12s} {\"speedup\":>8s}')\n",
    "print('-' * 105)\n",
    "for name in results:\n",
    "    incr = results[name]['incremental']\n",
    "    scratch = results[name]['from_scratch']\n",
    "    steady = incr[5:]\n",
    "    steady_s = scratch[5:]\n",
    "    final_total = incr[-1]['total_dfa_states']\n",
    "    med_expanded = np.median([r['n_expanded'] for r in steady])\n",
    "    med_dirty = np.median([r['n_dirty'] for r in steady])\n",
    "    med_border = np.median([r['n_border'] for r in steady])\n",
    "    med_time = np.median([r['time_s'] for r in steady]) * 1000\n",
    "    med_time_s = np.median([r['time_s'] for r in steady_s]) * 1000\n",
    "    speedup = med_time_s / med_time if med_time > 0 else float('inf')\n",
    "    print(f'{name:25s} {final_total:12d} {med_expanded:14.0f} {med_dirty:11.0f} {med_border:12.0f} {med_time:10.3f} {med_time_s:12.3f} {speedup:8.1f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct correlation: time vs. change size\n",
    "\n",
    "The left panel sweeps 15 FSTs (`doom(V, K)` with varying `|V|` and `K`, plus\n",
    "`triplets_of_doom`, `lookahead`, `duplicate`) to get a range of per-step change\n",
    "sizes (3\u201340 states expanded). Each point is one FST's steady-state median.\n",
    "Time is proportional to change size (R\u00b2 = 0.97).\n",
    "\n",
    "The right panel shows all 15 FSTs' raw per-step timings vs the total DFA size\n",
    "at that step. Each FST traces a horizontal band: as its DFA grows from tens to\n",
    "thousands of states, per-step time stays flat. The vertical position of each band\n",
    "is determined by the FST's change size, not the DFA size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_with_reps(fst, target_string, n_reps=5):\n",
    "    \"\"\"Collect per-step stats with repeated timing for robust medians.\"\"\"\n",
    "    records = []\n",
    "    for rep in range(n_reps):\n",
    "        s = TruncatedIncrementalDFADecomp(fst, '')\n",
    "        for i, y in enumerate(target_string):\n",
    "            t0 = time.perf_counter()\n",
    "            s = s >> y\n",
    "            dt = time.perf_counter() - t0\n",
    "            if rep == 0:\n",
    "                rec = dict(s._stats)\n",
    "                rec['step'] = i + 1\n",
    "                rec['times'] = [dt]\n",
    "                records.append(rec)\n",
    "            else:\n",
    "                records[i]['times'].append(dt)\n",
    "    for rec in records:\n",
    "        rec['time_s'] = np.median(rec['times'])\n",
    "    return records\n",
    "\n",
    "# Sweep doom(V, K) with varying |V| and K to get a range of change sizes\n",
    "M = 150\n",
    "sweep_fsts = []\n",
    "for k in [2, 3]:\n",
    "    for asize in [2, 3, 4, 5, 6, 8]:\n",
    "        alpha = [chr(ord('a') + i) for i in range(asize)]\n",
    "        V = set(alpha)\n",
    "        target = (''.join(alpha) * (M // asize + 1))[:M]\n",
    "        sweep_fsts.append((f'doom(|V|={asize}, K={k})', examples.doom(V, k), target))\n",
    "sweep_fsts += [\n",
    "    ('triplets of doom',  examples.triplets_of_doom(), 'a' * M),\n",
    "    ('lookahead',         examples.lookahead(),        ('ab' * 80)[:M]),\n",
    "    ('duplicate(5)',      examples.duplicate(set('12345')), ('1122334455' * 20)[:M]),\n",
    "]\n",
    "\n",
    "sweep_data = {}\n",
    "for name, fst, target in sweep_fsts:\n",
    "    sweep_data[name] = collect_with_reps(fst, target, n_reps=5)\n",
    "\n",
    "# --- Two-panel figure ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5.5))\n",
    "\n",
    "# LEFT: Across FSTs \u2014 steady-state time vs steady-state change size\n",
    "ss_expanded, ss_time, ss_labels = [], [], []\n",
    "for name, recs in sweep_data.items():\n",
    "    steady = recs[5:]\n",
    "    ss_expanded.append(np.median([r['n_expanded'] for r in steady]))\n",
    "    ss_time.append(np.median([r['time_s'] for r in steady]) * 1e6)\n",
    "    ss_labels.append(name)\n",
    "\n",
    "ss_expanded = np.array(ss_expanded)\n",
    "ss_time = np.array(ss_time)\n",
    "\n",
    "ax1.scatter(ss_expanded, ss_time, s=50, zorder=5, color='tab:blue', edgecolors='black', linewidths=0.5)\n",
    "slope = np.dot(ss_expanded, ss_time) / np.dot(ss_expanded, ss_expanded)\n",
    "xs = np.linspace(0, ss_expanded.max() * 1.05, 100)\n",
    "ax1.plot(xs, slope * xs, 'r--', linewidth=1.5, label=f'fit: {slope:.1f} \u03bcs/state')\n",
    "ss_res = np.sum((ss_time - slope * ss_expanded) ** 2)\n",
    "ss_tot = np.sum((ss_time - ss_time.mean()) ** 2)\n",
    "r2 = 1 - ss_res / ss_tot\n",
    "ax1.set_xlabel('states expanded per step (steady-state median)', fontsize=11)\n",
    "ax1.set_ylabel('time per step (\u03bcs, steady-state median)', fontsize=11)\n",
    "ax1.set_title(f'Across FSTs: time vs. change size\\nR\u00b2 = {r2:.2f}', fontsize=12)\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.set_xlim(left=0); ax1.set_ylim(bottom=0)\n",
    "for i, name in enumerate(ss_labels):\n",
    "    if any(tag in name for tag in ['triplet', 'lookahead', 'duplicate', '|V|=8']):\n",
    "        ax1.annotate(name, (ss_expanded[i], ss_time[i]),\n",
    "                     textcoords='offset points', xytext=(6, 4), fontsize=6.5, color='gray')\n",
    "\n",
    "# RIGHT: Within each FST \u2014 time vs total DFA size (should be flat)\n",
    "cmap = plt.cm.tab20\n",
    "for idx, (name, recs) in enumerate(sweep_data.items()):\n",
    "    steady = recs[5:]\n",
    "    totals = [r['total_dfa_states'] for r in steady]\n",
    "    times_us = [r['time_s'] * 1e6 for r in steady]\n",
    "    color = cmap(idx / len(sweep_data))\n",
    "    ax2.plot(totals, times_us, '.', color=color, markersize=3, alpha=0.4)\n",
    "    if len(times_us) > 10:\n",
    "        med = rolling_median(times_us, window=7)\n",
    "        label = name if idx < 8 else None\n",
    "        ax2.plot(totals, med, '-', color=color, linewidth=1.2, label=label)\n",
    "\n",
    "ax2.set_xlabel('total DFA states (growing over >> chain)', fontsize=11)\n",
    "ax2.set_ylabel('time per step (\u03bcs)', fontsize=11)\n",
    "ax2.set_title('Within each FST: time stays flat\\nas DFA grows', fontsize=12)\n",
    "ax2.legend(fontsize=6.5, loc='upper left', ncol=2)\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('reports/incremental_scaling_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}