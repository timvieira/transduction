{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pynini vs NLTK PTB Tokenizer — Adversarial Diff\n",
    "\n",
    "This notebook exercises known differences between the pynini FST and NLTK's `TreebankWordTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing PTB rules...\n",
      "Core PTB FST: 317 states\n",
      "Final pynini FST: 303 states\n",
      "Converting to native FST...\n",
      "Native FST: 303 states, 24545 arcs\n",
      "  eps: 111 in, 430 out\n",
      "  MARKER: 0 in, 0 out\n",
      "  [EOS]: 0 in, 0 out\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from benchmark.fsts.ptb_pynini import build_ptb_fst_pynini, string_to_byte_strs, SEP\n",
    "from transduction.fsa import EPSILON as NATIVE_EPSILON\n",
    "\n",
    "nltk_tok = TreebankWordTokenizer()\n",
    "fst = build_ptb_fst_pynini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.fst import FST\n",
    "\n",
    "\n",
    "def fst_tokenize(fst, text):\n",
    "    \"\"\"Tokenize text using the pynini-built FST.\"\"\"\n",
    "    byte_strs = string_to_byte_strs(text)\n",
    "    input_fst = FST.from_string(byte_strs)\n",
    "    output_fsa = fst(input_fst, None)\n",
    "    try:\n",
    "        output = next(output_fsa.language(tuple=True))\n",
    "    except StopIteration:\n",
    "        return None  # FST rejected input\n",
    "    tokens = []\n",
    "    current = []\n",
    "    for sym in output:\n",
    "        if sym == SEP:\n",
    "            if current:\n",
    "                tokens.append(bytes(int(b) for b in current).decode('utf-8', errors='replace'))\n",
    "                current = []\n",
    "        elif int(sym) < 256:\n",
    "            current.append(sym)\n",
    "    if current:\n",
    "        tokens.append(bytes(int(b) for b in current).decode('utf-8', errors='replace'))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def compare(text):\n",
    "    \"\"\"Compare NLTK and FST tokenization, highlighting differences.\"\"\"\n",
    "    n = nltk_tok.tokenize(text)\n",
    "    f = fst_tokenize(fst, text)\n",
    "    match = '✓' if n == f else '✗'\n",
    "    print(f'{match} {text!r}')\n",
    "    if n != f:\n",
    "        print(f'  NLTK:  {n}')\n",
    "        print(f'  FST:   {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Missing `#` in special punctuation\n",
    "\n",
    "NLTK separates `[;@#$%&]`, but pynini only has `[;@%&$]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 'Price is #100'\n",
      "✓ '##heading'\n",
      "✓ 'C# programming'\n"
     ]
    }
   ],
   "source": [
    "compare('Price is #100')\n",
    "compare('##heading')\n",
    "compare('C# programming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ALL CAPS contractions\n",
    "\n",
    "NLTK's CONTRACTIONS2 uses `(?i)` (case-insensitive). Pynini only handles lowercase + Title case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 'CANNOT STOP'\n",
      "✓ 'I WANNA GO'\n",
      "✓ 'GONNA BE GREAT'\n",
      "✓ 'GOTTA RUN'\n",
      "✓ 'LEMME SEE'\n",
      "✓ 'GIMME THAT'\n",
      "✗ 'cAnNoT stop'\n",
      "  NLTK:  ['cAn', 'NoT', 'stop']\n",
      "  FST:   ['cAnNoT', 'stop']\n"
     ]
    }
   ],
   "source": [
    "compare('CANNOT STOP')\n",
    "compare('I WANNA GO')\n",
    "compare('GONNA BE GREAT')\n",
    "compare('GOTTA RUN')\n",
    "compare('LEMME SEE')\n",
    "compare('GIMME THAT')\n",
    "compare('cAnNoT stop')  # mixed case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing contractions: `d'ye`, `more'n`\n",
    "\n",
    "Present in NLTK's CONTRACTIONS2 but absent from the pynini FST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"D'ye think so?\"\n",
      "✓ \"d'ye know\"\n",
      "✓ \"more'n enough\"\n",
      "✓ \"More'n I expected\"\n"
     ]
    }
   ],
   "source": [
    "compare(\"D'ye think so?\")\n",
    "compare(\"d'ye know\")\n",
    "compare(\"more'n enough\")\n",
    "compare(\"More'n I expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing CONTRACTIONS3: `'tis`, `'twas`\n",
    "\n",
    "NLTK splits `'tis` → `'t is` and `'twas` → `'t was`. Pynini doesn't handle these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"'Tis the season\"\n",
      "✓ \"'Twas the night\"\n",
      "✓ \"'tis nothing\"\n",
      "✓ \"'twas long ago\"\n"
     ]
    }
   ],
   "source": [
    "compare(\"'Tis the season\")\n",
    "compare(\"'Twas the night\")\n",
    "compare(\"'tis nothing\")\n",
    "compare(\"'twas long ago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Double single-quotes (`''`) as opening quote\n",
    "\n",
    "NLTK converts `''` to ` `` ` when used as opening quotes (STARTING_QUOTES rule 3). Pynini doesn't handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"She said ''hello'' there\"\n",
      "✓ \"''Hello,'' she replied\"\n"
     ]
    }
   ],
   "source": [
    "compare(\"She said ''hello'' there\")\n",
    "compare(\"''Hello,'' she replied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sanity checks (should all match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"I can't do it.\"\n",
      "✓ \"It's a test -- really!\"\n",
      "✓ \"Don't you think?\"\n",
      "✓ \"I'll go there.\"\n",
      "✓ \"We've been here.\"\n",
      "✓ '1,000 people'\n",
      "✓ 'at 3:00 PM'\n",
      "✓ 'items: none'\n",
      "✓ 'foo;bar'\n",
      "✓ '$100 & more'\n",
      "✓ '50% off @ store'\n"
     ]
    }
   ],
   "source": [
    "compare(\"I can't do it.\")\n",
    "compare(\"It's a test -- really!\")\n",
    "compare(\"Don't you think?\")\n",
    "compare(\"I'll go there.\")\n",
    "compare(\"We've been here.\")\n",
    "compare('1,000 people')\n",
    "compare('at 3:00 PM')\n",
    "compare('items: none')\n",
    "compare('foo;bar')\n",
    "compare('$100 & more')\n",
    "compare('50% off @ store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
