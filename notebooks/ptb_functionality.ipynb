{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Is the pynini PTB FST a function?\n",
    "\n",
    "An FST is a **function** if every input string maps to at most one output string.\n",
    "If some input can produce multiple distinct outputs, it's a **relation**.\n",
    "\n",
    "We test this by composing `FST.from_string(input) @ ptb_fst`, projecting onto the output,\n",
    "and checking whether the resulting FSA has more than one string in its language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from collections import deque\n",
    "from benchmark.fsts.ptb_pynini import build_ptb_fst_pynini, string_to_byte_strs, SEP\n",
    "from transduction.fst import FST\n",
    "from transduction.fsa import EPSILON\n",
    "\n",
    "fst = build_ptb_fst_pynini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(output_tuple):\n",
    "    \"\"\"Decode FST output tuple back to readable token string.\"\"\"\n",
    "    tokens = []\n",
    "    current = []\n",
    "    for sym in output_tuple:\n",
    "        if sym == SEP:\n",
    "            if current:\n",
    "                tokens.append(bytes(int(b) for b in current).decode('utf-8', errors='replace'))\n",
    "                current = []\n",
    "        elif sym != EPSILON and int(sym) < 256:\n",
    "            current.append(sym)\n",
    "    if current:\n",
    "        tokens.append(bytes(int(b) for b in current).decode('utf-8', errors='replace'))\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def enumerate_outputs(fst, text, max_outputs=20):\n",
    "    \"\"\"\n",
    "    Enumerate up to `max_outputs` distinct output strings for a given input text.\n",
    "    \n",
    "    Returns a list of distinct output tuples.\n",
    "    \"\"\"\n",
    "    byte_strs = string_to_byte_strs(text)\n",
    "    input_fst = FST.from_string(byte_strs)\n",
    "    output_fsa = (input_fst @ fst).project(1)\n",
    "    \n",
    "    # BFS enumeration with visited-state tracking to avoid infinite loops\n",
    "    seen_outputs = set()\n",
    "    results = []\n",
    "    worklist = deque()\n",
    "    for s in output_fsa.start:\n",
    "        worklist.append((s, (), set()))\n",
    "    \n",
    "    iterations = 0\n",
    "    max_iterations = 500_000  # safety limit\n",
    "    \n",
    "    while worklist and len(results) < max_outputs and iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        state, path, visited_with_path = worklist.popleft()\n",
    "        \n",
    "        if state in output_fsa.stop:\n",
    "            if path not in seen_outputs:\n",
    "                seen_outputs.add(path)\n",
    "                results.append(path)\n",
    "                if len(results) >= max_outputs:\n",
    "                    break\n",
    "        \n",
    "        for a, j in output_fsa.arcs(state):\n",
    "            if a == EPSILON:\n",
    "                # For epsilon transitions, track visited states to avoid cycles\n",
    "                key = (j, path)\n",
    "                if key not in visited_with_path:\n",
    "                    new_visited = visited_with_path | {key}\n",
    "                    worklist.append((j, path, new_visited))\n",
    "            else:\n",
    "                new_path = path + (a,)\n",
    "                worklist.append((j, new_path, set()))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def check_functional(fst, text, max_outputs=10):\n",
    "    \"\"\"\n",
    "    Check if the FST is functional on a given input.\n",
    "    Returns (is_functional, outputs_list).\n",
    "    \"\"\"\n",
    "    outputs = enumerate_outputs(fst, text, max_outputs=max_outputs)\n",
    "    return len(outputs) <= 1, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Quick sanity check\n",
    "\n",
    "A simple input should produce exactly one output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fn, outputs = check_functional(fst, \"Hello, world!\")\n",
    "print(f\"Functional: {is_fn}\")\n",
    "print(f\"Number of outputs: {len(outputs)}\")\n",
    "for o in outputs:\n",
    "    print(f\"  -> {decode_output(o)!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Curated test cases\n",
    "\n",
    "These target areas most likely to cause ambiguity:\n",
    "quotes, contractions, clitics, punctuation edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    # Basic\n",
    "    \"Hello world\",\n",
    "    \"Hello, world!\",\n",
    "    \n",
    "    # Contractions and clitics\n",
    "    \"I can't do it.\",\n",
    "    \"I'll be there.\",\n",
    "    \"We've been here.\",\n",
    "    \"Don't you think?\",\n",
    "    \"It's a test.\",\n",
    "    \"She'd gone home.\",\n",
    "    \n",
    "    # Contractions that split\n",
    "    \"cannot stop\",\n",
    "    \"gonna be great\",\n",
    "    \"gotta run\",\n",
    "    \"lemme see\",\n",
    "    \"wanna go\",\n",
    "    \"gimme that\",\n",
    "    \"CANNOT STOP\",\n",
    "    \"Cannot stop\",\n",
    "    \n",
    "    # Contractions3\n",
    "    \"'tis nothing\",\n",
    "    \"'twas long ago\",\n",
    "    \"'Tis the season\",\n",
    "    \n",
    "    # Quotes — potential ambiguity source\n",
    "    '\"Hello,\" she said.',\n",
    "    'She said \"hello\" to me.',\n",
    "    'He said \"don\\'t\" loudly.',\n",
    "    '\"Can\\'t stop,\" he said.',\n",
    "    \"''Hello,'' she replied\",\n",
    "    'She said ''hello'' there',\n",
    "    '\"\"double quotes\"\"',\n",
    "    \n",
    "    # Nested/adjacent quotes\n",
    "    '\"She said \\'hello\\',\" he replied.',\n",
    "    '\"It\\'s fine,\" she said.',\n",
    "    \n",
    "    # Punctuation\n",
    "    \"Hello...\",\n",
    "    \"What?!\",\n",
    "    \"a -- b\",\n",
    "    \"(hello) [world]\",\n",
    "    \"1,000 people\",\n",
    "    \"at 3:00 PM\",\n",
    "    \"items: none\",\n",
    "    \"$100 & more\",\n",
    "    \"50% off @ store\",\n",
    "    \n",
    "    # Period edge cases\n",
    "    \"Dr. Smith went home.\",\n",
    "    \"U.S.A.\",\n",
    "    \"end.\",\n",
    "    \"end. \",\n",
    "    \n",
    "    # Apostrophe edge cases\n",
    "    \"the dog's bone\",\n",
    "    \"the dogs' bones\",\n",
    "    \"rock 'n' roll\",\n",
    "    \"'twas brillig\",\n",
    "    \n",
    "    # Multiple clitics in one sentence\n",
    "    \"I can't believe she'd've done that.\",\n",
    "    \"They'll've gone by then.\",\n",
    "    \n",
    "    # Mixed contractions and quotes\n",
    "    '\"I can\\'t,\" she said.',\n",
    "    'He replied, \"We\\'ll see.\"',\n",
    "    \n",
    "    # Edge cases that might cause overlapping rule matches\n",
    "    \"''\",\n",
    "    '\"',\n",
    "    \"'\",\n",
    "    \"a'b\",\n",
    "    \"a''b\",\n",
    "    'a\"b',\n",
    "    \"d'ye know\",\n",
    "    \"more'n enough\",\n",
    "    \n",
    "    # Longer text\n",
    "    'The company reported $1,000,000 in revenue (a 50% increase), which \"exceeded expectations.\"',\n",
    "]\n",
    "\n",
    "non_functional = []\n",
    "\n",
    "for text in test_cases:\n",
    "    is_fn, outputs = check_functional(fst, text)\n",
    "    n = len(outputs)\n",
    "    status = '✓' if is_fn else f'✗ ({n} outputs)'\n",
    "    print(f\"{status} {text!r}\")\n",
    "    if not is_fn:\n",
    "        non_functional.append((text, outputs))\n",
    "        for o in outputs[:5]:\n",
    "            print(f\"    -> {decode_output(o)!r}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Functional: {len(test_cases) - len(non_functional)}/{len(test_cases)}\")\n",
    "print(f\"Non-functional: {len(non_functional)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Adversarial inputs\n",
    "\n",
    "Target overlapping rule contexts: contractions inside quotes, mixed punctuation,\n",
    "boundary conditions, adjacent special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial = [\n",
    "    # Contraction + clitic overlap\n",
    "    \"cannot's\", \"gimme's\", \"gonna's\",\n",
    "    # Contraction at sentence boundary\n",
    "    \"cannot.\", \"cannot!\", \"cannot?\",\n",
    "    # Contraction inside quotes\n",
    "    '\"cannot\"', '\"gimme\"', '\"gonna\"',\n",
    "    # Contraction adjacent to other contractions\n",
    "    \"cannot cannot\", \"I can't cannot go\",\n",
    "    # Multiple apostrophe patterns\n",
    "    \"it's 'cause\", \"she's 'n' he's\", \"'twas it's\",\n",
    "    # Quotes with contractions\n",
    "    \"\\\"I can't,\\\" she can't.\", \"''can't''\", '\"cannot stop\"',\n",
    "    # Period with quotes\n",
    "    'said \"hello.\"', \"said ''hello.''\", 'He said \"Dr. Smith.\"',\n",
    "    # Multiple punctuation\n",
    "    \"hello!!\", \"hello??\", \"hello?!\", \"hello!?\", \"a...b...c\",\n",
    "    # Brackets with quotes\n",
    "    '(\"hello\")', '[\"world\"]', '(cannot)',\n",
    "    # Edge: minimal inputs\n",
    "    \"a\", \"ab\", \" \", \"  \",\n",
    "    # Double-dash with quotes\n",
    "    '\"hello\" -- \"world\"', \"a--b--c\",\n",
    "    # Hash with context\n",
    "    \"#hello\", \"a#b\", \"100#\",\n",
    "    # Single character punctuation\n",
    "    \".\", \",\", \":\", \";\", \"!\", \"?\", \"@\", \"#\", \"%\", \"&\",\n",
    "    # Adjacent special chars\n",
    "    \"@#$%\", \".,;:!?\",\n",
    "    # Whitespace-sensitive\n",
    "    \" hello\", \"hello \", \" hello \", \"  hello  world  \",\n",
    "]\n",
    "\n",
    "adv_non_functional = []\n",
    "for text in adversarial:\n",
    "    is_fn, outputs = check_functional(fst, text)\n",
    "    n = len(outputs)\n",
    "    status = '✓' if is_fn else f'✗ ({n} outputs)'\n",
    "    print(f\"{status} {text!r}\")\n",
    "    if not is_fn:\n",
    "        adv_non_functional.append((text, outputs))\n",
    "        for o in outputs[:5]:\n",
    "            print(f\"    -> {decode_output(o)!r}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Adversarial: {len(adversarial) - len(adv_non_functional)}/{len(adversarial)} functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## WikiText paragraphs\n",
    "\n",
    "Test on 200 real-world paragraphs from WikiText-103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ai6s7dhj22o",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.data import load_wikitext, wikitext_detokenize\n",
    "\n",
    "dataset = load_wikitext('test')\n",
    "\n",
    "paragraphs = []\n",
    "for item in dataset:\n",
    "    text = item['text'].strip()\n",
    "    if text and not text.startswith('='):\n",
    "        detokenized = wikitext_detokenize(text)[:200]\n",
    "        if len(detokenized) > 10:\n",
    "            paragraphs.append(detokenized)\n",
    "    if len(paragraphs) >= 200:\n",
    "        break\n",
    "\n",
    "print(f\"Loaded {len(paragraphs)} paragraphs from WikiText\")\n",
    "\n",
    "wiki_non_functional = []\n",
    "for i, text in enumerate(paragraphs):\n",
    "    is_fn, outputs = check_functional(fst, text, max_outputs=5)\n",
    "    if not is_fn:\n",
    "        wiki_non_functional.append((text, outputs))\n",
    "        print(f\"✗ [{i}] ({len(outputs)} outputs) {text[:80]!r}\")\n",
    "        for o in outputs[:3]:\n",
    "            print(f\"    -> {decode_output(o)!r}\")\n",
    "    elif (i + 1) % 50 == 0:\n",
    "        print(f\"  ... checked {i + 1}/{len(paragraphs)}, {len(wiki_non_functional)} non-functional so far\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"WikiText: {len(paragraphs) - len(wiki_non_functional)}/{len(paragraphs)} functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Random stress test\n",
    "\n",
    "500 random strings from a punctuation-biased alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "random.seed(42)\n",
    "alphabet = string.ascii_letters + string.digits + \"  .,;:!?'\\\"()[]{}--@#$%&\"\n",
    "\n",
    "rand_non_functional = []\n",
    "n_tests = 500\n",
    "for i in range(n_tests):\n",
    "    length = random.randint(1, 30)\n",
    "    text = ''.join(random.choice(alphabet) for _ in range(length))\n",
    "    try:\n",
    "        is_fn, outputs = check_functional(fst, text, max_outputs=5)\n",
    "        if not is_fn:\n",
    "            rand_non_functional.append((text, outputs))\n",
    "            print(f\"✗ ({len(outputs)} outputs) {text!r}\")\n",
    "            for o in outputs[:3]:\n",
    "                print(f\"    -> {decode_output(o)!r}\")\n",
    "    except Exception:\n",
    "        pass  # skip errors from unusual byte sequences\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  ... tested {i+1}/{n_tests}, {len(rand_non_functional)} non-functional\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Random: {n_tests - len(rand_non_functional)}/{n_tests} functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nd050a3rsu",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dnnovufbh8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_non_functional = non_functional + adv_non_functional + wiki_non_functional + rand_non_functional\n",
    "\n",
    "if not all_non_functional:\n",
    "    print(\"RESULT: The PTB pynini FST is a FUNCTION.\")\n",
    "    print()\n",
    "    print(\"No input (out of ~790 tested) produced multiple distinct outputs.\")\n",
    "    print()\n",
    "    print(\"This is expected: each pynini cdrewrite rule is functional by construction,\")\n",
    "    print(\"and composition of functional FSTs preserves functionality.\")\n",
    "else:\n",
    "    print(f\"RESULT: The PTB FST is a RELATION — {len(all_non_functional)} inputs produced multiple outputs.\")\n",
    "    print()\n",
    "    for text, outputs in all_non_functional:\n",
    "        print(f\"Input: {text!r}\")\n",
    "        for o in outputs:\n",
    "            print(f\"  -> {decode_output(o)!r}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
