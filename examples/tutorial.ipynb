{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transduction Tutorial\n",
    "\n",
    "This notebook walks through the core concepts and APIs of the `transduction`\n",
    "library:\n",
    "\n",
    "1. **Building FSTs** — define finite-state transducers\n",
    "2. **Decomposition** — compute quotient and remainder for a target prefix\n",
    "3. **TransducedLM** — pushforward of a language model through an FST\n",
    "4. **Decoding** — greedy and sampled generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building an FST\n",
    "\n",
    "An FST maps **source** strings to **target** strings.  Each arc carries an\n",
    "input label (source side) and an output label (target side).  The empty\n",
    "string `''` represents epsilon (no symbol consumed/produced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.fst import FST, EPSILON\n",
    "\n",
    "# Build an FST by hand: lowercase normalizer for {a, b}\n",
    "# Maps both 'A'->'a' and 'a'->'a' (and similarly for b)\n",
    "fst = FST()\n",
    "fst.add_start(0)\n",
    "fst.add_stop(0)\n",
    "for ch in 'ab':\n",
    "    fst.add_arc(0, ch.lower(), ch.lower(), 0)  # 'a' -> 'a'\n",
    "    fst.add_arc(0, ch.upper(), ch.lower(), 0)  # 'A' -> 'a'\n",
    "\n",
    "fst  # renders as a Graphviz diagram in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.viz import display_table\n",
    "\n",
    "# Show the FST's relation as a rich table\n",
    "pairs = sorted(fst.relation(3))\n",
    "display_table(\n",
    "    [[repr(src), repr(tgt)] for src, tgt in pairs],\n",
    "    headings=['Source', 'Target'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also convenience constructors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# FST.from_string: identity transducer for a fixed string\n",
    "id_fst = FST.from_string('hello')\n",
    "display(id_fst)\n",
    "\n",
    "# FST.from_pairs: mapping from (input, output) symbol pairs\n",
    "replace_fst = FST.from_pairs([('a', 'x'), ('b', 'y')])\n",
    "display(replace_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `examples` module provides several pre-built FSTs for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction import examples\n",
    "\n",
    "# An FST with interesting decomposition behavior\n",
    "fst = examples.small()\n",
    "fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its relation (all source/target pairs up to length 4)\n",
    "display_table(\n",
    "    [[repr(s), repr(t)] for s, t in sorted(fst.relation(4))],\n",
    "    headings=['Source', 'Target'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decomposition: Quotient and Remainder\n",
    "\n",
    "Given a target prefix **y**, the *precover decomposition* splits the set of\n",
    "source strings that produce output beginning with **y** into:\n",
    "\n",
    "- **Quotient** Q(y): sources that produced **y** and can still continue.\n",
    "- **Remainder** R(y): sources that produced **y** and have terminated.\n",
    "\n",
    "The Q and R are represented as **FSAs** (finite-state acceptors).  Let's\n",
    "visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.rust_bridge import RustDecomp\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "result = RustDecomp(fst, 'x')\n",
    "\n",
    "display(HTML('<h4>Quotient Q(\"x\") — sources that can still continue:</h4>'))\n",
    "display(result.quotient)\n",
    "\n",
    "display(HTML('<h4>Remainder R(\"x\") — sources that have terminated:</h4>'))\n",
    "display(result.remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `>>` operator extends the target prefix **incrementally**, reusing\n",
    "computation from the previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.rust_bridge import RustDirtyState\n",
    "\n",
    "state = RustDirtyState(fst)\n",
    "state = state >> 'x'\n",
    "\n",
    "display(HTML('<h4>After target \"x\" — Quotient:</h4>'))\n",
    "display(state.quotient)\n",
    "display(HTML('<h4>After target \"x\" — Remainder:</h4>'))\n",
    "display(state.remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2 = state >> 'a'\n",
    "\n",
    "display(HTML('<h4>After target \"xa\" — Quotient:</h4>'))\n",
    "display(state2.quotient)\n",
    "display(HTML('<h4>After target \"xa\" — Remainder:</h4>'))\n",
    "display(state2.remainder)  # empty — no source string terminates here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TransducedLM\n",
    "\n",
    "The `TransducedLM` computes the **pushforward** of an inner language model\n",
    "through an FST.  It maintains a beam of K particles (source-prefix\n",
    "hypotheses) and uses the decomposition to score each next target symbol.\n",
    "\n",
    "The API mirrors the inner LM:\n",
    "```python\n",
    "state = tlm >> 'h'          # advance by target symbol\n",
    "p = state.logp_next['e']    # log P(e | target_so_far)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transduction.lm.ngram import CharNgramLM\n",
    "from transduction.lm.transduced import TransducedLM\n",
    "\n",
    "# Train a character-level n-gram LM on mixed-case text\n",
    "inner_lm = CharNgramLM.train('Hello World hello world the hero held', n=3)\n",
    "\n",
    "# Build the transduced LM (lowercase FST, K=50 particles)\n",
    "fst = examples.lowercase()\n",
    "tlm = TransducedLM(inner_lm, fst, K=50)\n",
    "tlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: P_target('h') = P_source('h') + P_source('H')\n",
    "# because both map to the same target symbol through the FST.\n",
    "s0 = inner_lm.initial()\n",
    "p_h = np.exp(s0.logp_next['h'])\n",
    "p_H = np.exp(s0.logp_next['H'])\n",
    "\n",
    "state = tlm.initial()\n",
    "p_target_h = np.exp(state.logp_next['h'])\n",
    "\n",
    "display_table(\n",
    "    [\n",
    "        ['P_source(h)', f'{p_h:.4f}'],\n",
    "        ['P_source(H)', f'{p_H:.4f}'],\n",
    "        ['sum', f'{p_h + p_H:.4f}'],\n",
    "        ['P_target(h)', f'{p_target_h:.4f}'],\n",
    "    ],\n",
    "    headings=['Quantity', 'Value'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition on target prefix \"he\" — TransducedState has rich HTML display\n",
    "# showing particles, DFA states, and the next-symbol distribution.\n",
    "state = tlm >> 'h' >> 'e'\n",
    "state  # _repr_html_ renders particle table + logp_next distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decoding\n",
    "\n",
    "`TransducedLM` supports greedy and sampled decoding out of the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy decode\n",
    "tokens = tlm.initial().greedy_decode(max_len=20)\n",
    "display(HTML(f'<b>Greedy:</b> <code>{\"\" .join(tokens)}</code>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample decode\n",
    "np.random.seed(42)\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    tokens = tlm.initial().sample_decode(max_len=20)\n",
    "    samples.append([str(i+1), repr(''.join(tokens))])\n",
    "\n",
    "display_table(samples, headings=['#', 'Sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FSA Operations\n",
    "\n",
    "The `FSA` class supports the full suite of regular-language operations.\n",
    "These are used internally by the decomposition algorithms but are also\n",
    "useful on their own.  All FSAs render as Graphviz diagrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.fsa import FSA\n",
    "\n",
    "a = FSA.from_string('ab')\n",
    "b = FSA.from_string('cd')\n",
    "\n",
    "display(HTML('<h4>FSA for \"ab\":</h4>'))\n",
    "display(a)\n",
    "\n",
    "display(HTML('<h4>Union (ab | cd):</h4>'))\n",
    "display(a + b)\n",
    "\n",
    "display(HTML('<h4>Concatenation (ab · cd):</h4>'))\n",
    "display(a * b)\n",
    "\n",
    "display(HTML('<h4>Kleene star (ab)*:</h4>'))\n",
    "display(a.star())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinization and minimization\n",
    "nfa = a + b\n",
    "dfa = nfa.det()\n",
    "minimal = dfa.min_fast()\n",
    "\n",
    "display_table(\n",
    "    [\n",
    "        ['NFA (union)', str(len(nfa.states))],\n",
    "        ['DFA (det)', str(len(dfa.states))],\n",
    "        ['Minimal', str(len(minimal.states))],\n",
    "        ['Languages equal?', str(dfa.equal(minimal))],\n",
    "    ],\n",
    "    headings=['Automaton', 'States / Result'],\n",
    ")\n",
    "\n",
    "display(HTML('<h4>Minimized DFA:</h4>'))\n",
    "display(minimal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}