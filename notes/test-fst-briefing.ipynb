{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Test FST Briefing\n\nA catalog of the **30 FST constructors** in `transduction.examples`,\norganized by what makes each one interesting for testing decomposition\nalgorithms.\n\n`test_general.py` uses 18 of these across **9 algorithm implementations**\n(6 Python + 3 Rust). Each test recursively calls `decompose_next()` and\nverifies the quotient/remainder pair against the reference `Precover`.\nThe remaining FSTs are used in `test_finite.py`, `test_push_labels.py`,\nor serve as building blocks.\n\n### Implementations in test_general.py\n\n| Implementation | Lang | Incremental | Notes |\n|----------------|:----:|:-----------:|-------|\n| TruncatedIncrementalDFADecomp | Py | ✓ | Dirty-state + truncation |\n| NonrecursiveDFADecomp | Py | | Full recomputation each step |\n| PeekabooState | Py | ✓ | Per-symbol Q/R via peekaboo |\n| PeekabooNonrecursive | Py | | Non-incremental peekaboo |\n| DirtyPeekaboo | Py | ✓ | Dirty-state peekaboo |\n| TokenDecompose | Py | ✓ | BPE fast path (aiu only) |\n| RustDecomp | Rs | | Full powerset decomposition |\n| RustDirtyState | Rs | ✓ | Dirty-state incremental |\n| RustDirtyPeekaboo | Rs | ✓ | Dirty-state peekaboo |",
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from transduction import examples, FST, EPSILON, Precover\nfrom transduction.universality import compute_ip_universal_states, check_all_input_universal\nfrom IPython.display import display, Markdown\n\ntry:\n    from transduction.rust_bridge import to_rust_fst\n    import transduction_core\n    HAS_RUST = True\nexcept ImportError:\n    HAS_RUST = False\n\ndef brief(fst, name):\n    aiu = check_all_input_universal(fst)\n    ip = compute_ip_universal_states(fst)\n    is_fun, _ = fst.is_functional()\n    n = len(list(fst.states))\n    print(f'{name}: {n} states, |A|={len(fst.A - {EPSILON})}, |B|={len(fst.B - {EPSILON})}')\n    print(f'  all_input_universal={aiu}, ip_universal={sorted(ip)} ({len(ip)}/{n}), functional={is_fun}')\n\ndef rust_stats(fst, target_syms):\n    if not HAS_RUST:\n        print('  (Rust not available)'); return\n    rust_fst, sym_map, _ = to_rust_fst(fst)\n    target_u32 = [sym_map(y) for y in target_syms]\n    s = transduction_core.rust_decompose(rust_fst, target_u32).stats\n    print(f'  DFA: {s.dfa_states} states, {s.total_arcs} arcs')\n    print(f'  universality: {s.universal_calls} calls ({s.universal_true} T, {s.universal_false} F), sub_bfs={s.universal_sub_bfs_states}')",
   "execution_count": null,
   "outputs": [],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Overview\n\nAll 30 example FSTs at a glance.\n\n- **fun**: is a (partial) function (required for peekaboo agreement)\n- **aiu**: `check_all_input_universal` (enables TokenDecompose fast path)\n- **ip**: count of ip-universal states / total states\n- **tests**: G = `test_general.py`, F = `test_finite.py`, P = `test_push_labels.py`",
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\n\nall_fsts = [\n    ('replace',              examples.replace([('1','a'),('2','b'),('3','c'),('4','d'),('5','e')])),\n    ('delete_b',             examples.delete_b()),\n    ('duplicate',            examples.duplicate(set('12345'))),\n    ('weird_copy',           examples.weird_copy()),\n    ('togglecase',           examples.togglecase()),\n    ('lowercase',            examples.lowercase()),\n    ('small',                examples.small()),\n    ('samuel_example',       examples.samuel_example()),\n    ('sdd1_fst',             examples.sdd1_fst()),\n    ('lookahead',            examples.lookahead()),\n    ('mystery1',             examples.mystery1()),\n    ('mystery2',             examples.mystery2()),\n    ('mystery3',             examples.mystery3()),\n    ('mystery4',             examples.mystery4()),\n    ('mystery5',             examples.mystery5()),\n    ('mystery6',             examples.mystery6()),\n    ('mystery7',             examples.mystery7()),\n    ('mystery8',             examples.mystery8()),\n    ('newspeak2',            examples.newspeak2()),\n    ('number_comma_sep',     examples.number_comma_separator({'a',',', ' ','0'}, Digit={'0'})),\n    ('parity',               examples.parity({'a','b'})),\n    ('triplets_of_doom',     examples.triplets_of_doom()),\n    ('doom(K=4)',            examples.doom({'a','b'}, 4)),\n    ('infinite_quotient',    examples.infinite_quotient()),\n    ('infinite_quotient2',   examples.infinite_quotient2()),\n    ('gated_universal',      examples.gated_universal()),\n    ('complementary_halves', examples.complementary_halves()),\n    ('shrinking_nonuniv',    examples.shrinking_nonuniversal()),\n    ('scaled_newspeak',      examples.scaled_newspeak(n_patterns=3, alpha_size=6)),\n    ('layered_witnesses',    examples.layered_witnesses()),\n]\nfst_of = {name: fst for name, fst in all_fsts}\n\ntest_coverage = {\n    'replace': 'GF', 'delete_b': 'GFP', 'duplicate': 'GF', 'weird_copy': 'GP',\n    'togglecase': '', 'lowercase': '',\n    'small': 'GP', 'samuel_example': 'GFP', 'sdd1_fst': 'GF', 'lookahead': 'GP',\n    'mystery1': 'P', 'mystery2': '', 'mystery3': 'P', 'mystery4': 'P', 'mystery5': 'P',\n    'mystery6': '', 'mystery7': 'P', 'mystery8': 'P',\n    'newspeak2': 'GF', 'number_comma_sep': 'GF', 'parity': 'GP',\n    'triplets_of_doom': 'G', 'doom(K=4)': '', 'infinite_quotient': 'G', 'infinite_quotient2': '',\n    'gated_universal': 'G', 'complementary_halves': 'G', 'shrinking_nonuniv': 'G',\n    'scaled_newspeak': 'G', 'layered_witnesses': 'G',\n}\n\nrows = []\nfor name, fst in all_fsts:\n    n = len(list(fst.states))\n    ip = len(compute_ip_universal_states(fst))\n    is_fun, _ = fst.is_functional()\n    rows.append({\n        'name': name,\n        '|Q|': n,\n        '|A|': len(fst.A - {EPSILON}),\n        '|B|': len(fst.B - {EPSILON}),\n        'fun': is_fun,\n        'aiu': check_all_input_universal(fst),\n        'ip': f'{ip}/{n}',\n        '\\u03b5-in': EPSILON in fst.A,\n        '\\u03b5-out': EPSILON in fst.B,\n        'tests': test_coverage.get(name, '') or '\\u2014',\n    })\ndf = pd.DataFrame(rows).set_index('name')\ndf",
   "execution_count": null,
   "outputs": [],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## All-input-universal FSTs\n\nWhen every FST state is ip-universal (its input projection accepts Σ\\*),\nthe quotient at each decomposition step is Σ\\* and the remainder carries\nall the constraints. This enables `TokenDecompose`, the BPE fast path that\nskips powerset construction entirely.\n\nSix example FSTs have this property:\n\n- **replace** — symbol-for-symbol substitution (test_abc uses 1→a, 2→b, …)\n- **delete_b** — deletes `b`, maps `a→A`. Infinite quotients (`b*` in every quotient).\n- **duplicate** — repeats each symbol K times: `abc → aabbcc`\n- **weird_copy** — identity with ε-input arcs back to start\n- **togglecase** — swaps case: a↔A, b↔B, … (53-symbol alphabet, not tested)\n- **lowercase** — maps uppercase to lowercase (53-symbol alphabet, not tested)",
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "for name in ['replace', 'delete_b', 'duplicate', 'weird_copy', 'togglecase', 'lowercase']:\n    brief(fst_of[name], name)\n    display(fst_of[name])\n    print()",
   "execution_count": null,
   "outputs": [],
   "id": "cell-5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Epsilon structure\n\nThese FSTs use ε-output arcs (emit nothing while consuming input) or\nε-input arcs (emit output without consuming input). The precover NFA\ntracks a **target buffer** of pending output symbols. This tests that\nthe powerset determinization correctly handles buffer accumulation across\nnondeterministic branches.",
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### small, samuel_example, sdd1_fst\n\nThree compact FSTs with different epsilon patterns:\n- **small** — branching with one ε-output arc, delayed emission\n- **samuel_example** — multiple ε-output arcs creating parallel precover paths\n- **sdd1_fst** — ε-input arc creating a parallel start path",
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "for name in ['small', 'samuel_example', 'sdd1_fst']:\n    brief(fst_of[name], name)\n    display(fst_of[name])\n    print()",
   "execution_count": null,
   "outputs": [],
   "id": "cell-8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### lookahead\n\nThe most complex ε-output example. A chain of ε-output arcs creates\nprecover NFA states with long target buffers — the FST \"looks ahead\" by\nconsuming input early and emitting output later.",
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['lookahead']\nbrief(fst, 'lookahead')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "B = sorted(fst.B - {EPSILON})\nP = Precover(fst, tuple(B[:3]))\ndisplay(P)\nP.show_decomposition()",
   "execution_count": null,
   "outputs": [],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### mystery1, mystery2, mystery7, mystery8\n\nFour FSTs exploring variations of ε-consuming paths. Each offers\nmultiple routes to the same output — a direct arc vs. one or more\nε-consuming steps followed by emission. Used primarily in\n`test_push_labels.py`.\n\n- **mystery1** — two paths to `c`: direct `a→c` or ε-consuming `b→ε` then `a→c`\n- **mystery2** — three paths: direct, two-step, and triple-ε\n- **mystery7** — two paths to `c` via different state routes, then `x`-loop\n- **mystery8** — mixed direct and ε-consuming paths with final accepting state",
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "for name in ['mystery1', 'mystery2', 'mystery7', 'mystery8']:\n    brief(fst_of[name], name)\n    display(fst_of[name])\n    print()",
   "execution_count": null,
   "outputs": [],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### mystery6 — the only non-functional FST\n\n`mystery6` is the **only FST in `examples.py` that is not a function**.\nIt has two paths that produce *different outputs* for the same input,\nmaking it a genuine relation. This means peekaboo decompositions will\n**not** agree with Precover on this FST, which is why it's excluded from\n`test_general.py`.",
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['mystery6']\nbrief(fst, 'mystery6')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conditional / delayed output\n\nThese FSTs consume input without emitting, then produce output at the\nend via ε-output arcs. The output depends on a property of the entire\ninput string (last symbol, count, parity, etc.).\n\n- **parity** — emits `0` or `1` based on even/odd input length\n- **mystery3** — emits `A` or `B` depending on whether the last symbol was `a` or `b`\n- **mystery4** — emits `1` if exactly one `a` in input, else `0`\n- **mystery5** — emits `0`, `1`, or `2` based on input length mod 3",
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "for name in ['parity', 'mystery3', 'mystery4', 'mystery5']:\n    brief(fst_of[name], name)\n    display(fst_of[name])\n    print()",
   "execution_count": null,
   "outputs": [],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Application-scale FSTs\n\nLarger alphabets and more states, approaching the complexity of\nreal-world transducers.",
   "id": "cell-18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### newspeak2\n\nReplaces `\"bad\" → \"ungood\"` over the 26-letter English alphabet.\nWith 8 states, 85 arcs, and |B|=26, this is the largest hand-coded FST.\nTested at depth 1 (with three starting targets) because the branching\nfactor is 26.",
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['newspeak2']\nbrief(fst, 'newspeak2')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### number_comma_separator\n\nA stateful formatting transducer: inserts `|` separators after commas in\nnumber sequences (`\"1, 2, 3\" → \"1,| 2,| 3\"`). The **only test that\nexercises non-empty initial targets** — `run_test` is called three times:\n\n1. `target=''` at depth 4 (from root)\n2. `target='0,| 0,'` at depth 1 (mid-sequence)\n3. `target='0,| 0,|'` at depth 1 (post-separator)",
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['number_comma_sep']\nbrief(fst, 'number_comma_separator')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-22"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Termination stress tests\n\nGeneral-case algorithms must terminate on FSTs with **infinite quotient\nand remainder languages**. The key mechanism is **target-buffer truncation**:\nwhen the powerset determinization discovers a universal DFA state (one that\naccepts Σ\\*), it truncates the precover NFA buffer, bounding the state space.\n\nAlgorithms without truncation (`LazyIncremental`, etc.) diverge on these\nFSTs — that's why they're excluded from `test_general.py`.",
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### triplets_of_doom\n\nThe quintessential termination test. A copy transducer for `(a³|b³)*`.\nHistorically significant: the first example that demonstrated the need for\ntarget-buffer truncation. Without it, each arc appends to the buffer and\nthe powerset DFA construction never terminates.\n\nTested at **depth 13** — far deeper than any other test.",
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['triplets_of_doom']\nbrief(fst, 'triplets_of_doom')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-25"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "P = Precover(fst, ('a', 'a', 'a'))\ndisplay(P)\nP.show_decomposition()\n\nif HAS_RUST:\n    print('\\nRust stats at increasing target lengths:')\n    for tlen in [3, 6, 13]:\n        print(f'  target_len={tlen}:')\n        rust_stats(fst, tuple('a' for _ in range(tlen)))",
   "execution_count": null,
   "outputs": [],
   "id": "cell-26"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### doom\n\nThe generalization of `triplets_of_doom`: a copy transducer for\n`(a^K | b^K)*` parameterized by alphabet V and repeat count K.\n`triplets_of_doom()` = `doom({'a','b'}, 3)`. Shown here with K=4.",
   "id": "cell-27"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['doom(K=4)']\nbrief(fst, 'doom(K=4)')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-28"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### infinite_quotient\n\nThe FST absorbs unbounded input in one state, then emits a constant.\nThe quotient language is infinite (strings of all lengths), but the\npowerset DFA state is universal, so truncation kicks in immediately.",
   "id": "cell-29"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['infinite_quotient']\nbrief(fst, 'infinite_quotient')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-30"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### infinite_quotient2\n\nTracks parity of `a` count, absorbs input after `#` separator, and\nemits the parity at the end via ε-output. Combines the infinite-quotient\nproperty with conditional output. Not currently in any test file.",
   "id": "cell-31"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['infinite_quotient2']\nbrief(fst, 'infinite_quotient2')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-32"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Universality filter hierarchy\n\nDuring powerset determinization, the algorithm repeatedly checks whether\na DFA state is **universal** (accepts Σ\\*). The `UniversalityFilter`\noptimizes this with a 5-level hierarchy:\n\n| Level | Name | Cost | Mechanism |\n|-------|------|------|----------|\n| 1 | `all_input_universal` fast path | O(1) | Every FST state is ip-universal ⇒ all DFA states universal |\n| 2 | ip-universal witness check | O(\\|S\\|) | Powerset S contains a known ip-universal element |\n| 3 | Positive cache (superset mono.) | O(\\|S\\|) | Cached universal U ⊆ S ⇒ S universal |\n| 4 | Negative cache (subset mono.) | O(\\|S\\|) | S ⊆ cached non-universal ⇒ S non-universal |\n| 5 | BFS fallback | O(\\|DFA\\|) | Full BFS; result cached |\n\nFive FSTs are designed so that a specific level is the *first* one that\nresolves universality. All five are **partial functions** (required for\npeekaboo agreement).",
   "id": "cell-33"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### gated_universal — *witness check (level 2)*\n\nNon-final gate dispatches to an ip-universal sink and a partial sink.\nThe powerset always contains the ip-universal witness — universality\nresolves without BFS.",
   "id": "cell-34"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['gated_universal']\nbrief(fst, 'gated_universal')\ndisplay(fst)\n\nif HAS_RUST:\n    print('\\nRust stats:')\n    for tlen in [3, 5, 10]:\n        print(f'  target_len={tlen}:')\n        rust_stats(fst, tuple('y' for _ in range(tlen)))",
   "execution_count": null,
   "outputs": [],
   "id": "cell-35"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### complementary_halves — *BFS + positive cache (levels 5, 3)*\n\nFour states over {a,b,c,d}, each covering half the alphabet.\nNo state is ip-universal. Universality of {1,2,3,4} requires\n**BFS fallback**; subsequent queries hit the **positive cache**.",
   "id": "cell-36"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['complementary_halves']\nbrief(fst, 'complementary_halves')\ndisplay(fst)\n\nif HAS_RUST:\n    print('\\nRust stats:')\n    for tlen in [3, 5, 10]:\n        print(f'  target_len={tlen}:')\n        rust_stats(fst, tuple('y' for _ in range(tlen)))",
   "execution_count": null,
   "outputs": [],
   "id": "cell-37"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### shrinking_nonuniversal — *negative cache (level 4)*\n\nThree states, none covering `c`. Powerset {1,2,3} is **not universal**.\nOn subsequent steps the powerset shrinks; subsets are recognized as\nnon-universal via the **negative cache**.\n\n**No universal states at all**: q_stops=0, every step produces a remainder.",
   "id": "cell-38"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['shrinking_nonuniv']\nbrief(fst, 'shrinking_nonuniversal')\ndisplay(fst)\n\nif HAS_RUST:\n    print('\\nRust stats:')\n    for tlen in [3, 5, 10]:\n        print(f'  target_len={tlen}:')\n        rust_stats(fst, tuple('y' for _ in range(tlen)))",
   "execution_count": null,
   "outputs": [],
   "id": "cell-39"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### scaled_newspeak — *all states ip-universal (level 2 via witness)*\n\nMulti-pattern replacement: every state has arcs on every input symbol\nand is final. All states are ip-universal, but `check_all_input_universal()`\nreturns False (sufficient condition fails), so the **witness check**\nhandles universality.\n\nExposes the gap between `compute_ip_universal_states()` (exact) and\n`check_all_input_universal()` (conservative).",
   "id": "cell-40"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['scaled_newspeak']\nbrief(fst, 'scaled_newspeak')\ndisplay(fst)",
   "execution_count": null,
   "outputs": [],
   "id": "cell-41"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### layered_witnesses — *witness check at scale (level 2)*\n\nChain of gate/universal/partial layers. Despite combinatorial powerset\nblowup, the witness check resolves every universality query in O(|S|).",
   "id": "cell-42"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fst = fst_of['layered_witnesses']\nbrief(fst, 'layered_witnesses')\ndisplay(fst)\n\nif HAS_RUST:\n    print('\\nRust stats across layer counts and target lengths:')\n    for n_layers, tlen in [(3, 5), (5, 10), (10, 15)]:\n        fst_scaled = examples.layered_witnesses(n_layers=n_layers)\n        ip = compute_ip_universal_states(fst_scaled)\n        n = len(list(fst_scaled.states))\n        print(f'  layers={n_layers}, tlen={tlen} ({n} states, {len(ip)} ip-universal):')\n        rust_stats(fst_scaled, tuple('y' for _ in range(tlen)))",
   "execution_count": null,
   "outputs": [],
   "id": "cell-43"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Observations\n\n**29 of 30 FSTs are (partial) functions.** Only `mystery6` is a genuine\nrelation. Functionality is required because peekaboo algorithms only agree\nwith Precover on functional transducers.\n\n**6 FSTs are all-input-universal** (replace, delete_b, duplicate,\nweird_copy, togglecase, lowercase). Only these run `TokenDecompose`.\n\n**12 FSTs are not in any test file**: doom, infinite_quotient2,\ntogglecase, lowercase, mystery2, mystery6 are available as examples\nbut not exercised by the test suite.\n\n**Test depth varies from 1 to 13**, chosen to balance coverage against\nruntime — each level multiplies recursive calls by |B|.\n\n**The 5 universality-filter FSTs** are the only tests specifically\ndesigned to probe the optimization hierarchy. The other 13 in\n`test_general.py` exercise universality incidentally.\n\n**`number_comma_separator` is the only test with non-empty initial targets**,\ntesting that algorithms correctly resume from arbitrary target positions.",
   "id": "cell-44"
  }
 ]
}