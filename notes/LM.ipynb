{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1206ef-cfc9-43fd-b738-dbd8bc26441a",
   "metadata": {},
   "source": [
    "# Transducing Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2748ec72-14ee-4237-8e86-282b51393aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72743ca-7241-45b7-af52-1ee3a68c5111",
   "metadata": {},
   "outputs": [],
   "source": "from transduction import FST, FSA, EPSILON, examples, Precover\nfrom transduction.enumeration import prioritized_enumeration, crude_importance_sampling, importance_sampling, logsumexp\nfrom transduction.viz import display_table\n\nimport numpy as np"
  },
  {
   "cell_type": "markdown",
   "id": "a5b14ce6-b066-4cab-980c-31d2bcd1837e",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "* I would favor moving to a general \"prioritize however you see fit\" design rather than hardcoding the LM prefix probability as the only design.\n",
    "\n",
    "* For example, it may be possible to view trimming (or approximate trimming from co-accessibility in a coarse-grained precover) as a kind of priorization heuristic.\n",
    "  \n",
    "* I would prefer to defer rather than prune so that we have good methods for recovering from dead ends.\n",
    "\n",
    "* I like to think of the enumeration algorithm as a prioritized materialization for the cross-production construction of the LM and the FST.  In the case of a neural language model, the LM's state space is the infinitely large and degenerate space of string prefixes.  We can contrast that with the case of a PFsA, where states come from a finite set.  How about PCFGs?  (The Bar-Hillel construction creates states of the form `(i,X,j)` where `i` and `j` are states of the automaton and `X` is a nonterminal in the PCFG.  It seems a little different that we triplets rather than pairs, but maybe there is an elegant way to reconcile this.) \n",
    "\n",
    "* It would be really nice if our enumeration method recovered exact algorithms when run on models with finitely many states (e.g., PCFG language models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d2a3d-6eea-428f-998a-cfbe40ab0556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0eef7b-56be-4251-8dfa-e8967eedec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abc2f03-7f86-4fb0-86a1-3561580e9a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"72pt\" height=\"76pt\"\n",
       " viewBox=\"0.00 0.00 72.00 76.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 72)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-72 68,-72 68,4 -4,4\"/>\n",
       "<!-- start_0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>start_0</title>\n",
       "<ellipse fill=\"black\" stroke=\"black\" cx=\"0\" cy=\"-11.5\" rx=\"0\" ry=\"0\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.67,-19C52.67,-19 48.33,-19 48.33,-19 46.17,-19 44,-16.83 44,-14.67 44,-14.67 44,-8.33 44,-8.33 44,-6.17 46.17,-4 48.33,-4 48.33,-4 52.67,-4 52.67,-4 54.83,-4 57,-6.17 57,-8.33 57,-8.33 57,-14.67 57,-14.67 57,-16.83 54.83,-19 52.67,-19\"/>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54,-23C54,-23 47,-23 47,-23 43.5,-23 40,-19.5 40,-16 40,-16 40,-7 40,-7 40,-3.5 43.5,0 47,0 47,0 54,0 54,0 57.5,0 61,-3.5 61,-7 61,-7 61,-16 61,-16 61,-19.5 57.5,-23 54,-23\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-9.6\" font-family=\"Monospace\" font-size=\"8.00\">0</text>\n",
       "</g>\n",
       "<!-- start_0&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>start_0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1.14,-11.5C2.98,-11.5 22.76,-11.5 36.44,-11.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"36.77,-12.55 39.77,-11.5 36.77,-10.45 36.77,-12.55\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.27,-23.01C43.32,-31.91 45.06,-41 50.5,-41 55.26,-41 57.19,-34.04 56.28,-26.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.26,-25.79 55.73,-23.01 55.19,-26.14 57.26,-25.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-61.6\" font-family=\"Monospace\" font-size=\"8.00\">a</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-52.6\" font-family=\"Monospace\" font-size=\"8.00\">b</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-43.6\" font-family=\"Monospace\" font-size=\"8.00\">c</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "FST(1 states)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fst = examples.replace([('a', 'a'), ('b', 'b'), ('c', 'c')])\n",
    "fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0efc13cb-0117-48dd-9919-c7d97acf34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genparse import EarleyLM, EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ef104-338e-4ee6-b33e-d338f14b977c",
   "metadata": {},
   "outputs": [],
   "source": "lm = EarleyLM.from_string(\"\"\"\n\n.5: S -> a S\n.4: S -> b S\n.1: S -> c\n\n\"\"\")\nlm.logp_next = lambda x: {k: np.log(v) if v > 0 else float('-inf') for k, v in lm.p_next(x).items()}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b909289-b39a-4df0-a12b-4b4f73da5721",
   "metadata": {},
   "outputs": [],
   "source": "class StatefulLM:\n    \"\"\"Wraps a stateless LM (e.g., genparse.EarleyLM) into the stateful\n    interface expected by prioritized_enumeration.\n\n    The wrapped LM must support ``p_next(context) -> dict-like`` returning\n    next-token probabilities given a context sequence.\n\n    This wrapper provides:\n      - ``.eos``       — the end-of-sequence token\n      - ``.logp_next`` — dict mapping next tokens to log-probabilities\n      - ``>> token``   — returns a new state with *token* appended to context\n\n    Example::\n\n        from genparse import EarleyLM, EOS\n        lm = StatefulLM(EarleyLM.from_string(\"...\"), eos=EOS)\n    \"\"\"\n\n    def __init__(self, lm, eos, context=()):\n        self._lm = lm\n        self._eos = eos\n        self._context = context\n\n    @property\n    def eos(self):\n        return self._eos\n\n    @property\n    def logp_next(self):\n        p = self._lm.p_next(self._context)\n        return {k: np.log(v) if v > 0 else float('-inf')\n                for k, v in p.items()}\n\n    def __rshift__(self, token):\n        return StatefulLM(self._lm, self._eos, self._context + (token,))\n\n    def __repr__(self):\n        return f'StatefulLM({list(self._context)})'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a8763-c022-4a4d-9aa4-fec2317a4b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bef5133-1c53-48f2-8ac5-9249cf48bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop: Item(0.000, {(0, '')}, StatefulLM([]))\n",
      "pop: Item(-0.693, {(0, 'a')}, StatefulLM(['a']))\n",
      "pop: Item(-1.609, {(0, 'ab')}, StatefulLM(['a', 'b']))\n",
      "pop: Item(-3.912, {(0, 'abc')}, StatefulLM(['a', 'b', 'c']))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transduction.enumeration.prioritized_enumeration at 0x746100e8a950>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prioritized_enumeration(StatefulLM(lm, EOS), fst, 'abc', max_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dc2897a-3aee-4b06-8572-e55baeb90eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop: Item(0.000, {(0, '')}, StatefulLM([]))\n",
      "pop: Item(-0.693, {(0, 'a')}, StatefulLM(['a']))\n",
      "pop: Item(-1.386, {(0, 'aa')}, StatefulLM(['a', 'a']))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transduction.enumeration.prioritized_enumeration at 0x746100e8b310>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prioritized_enumeration(StatefulLM(lm, EOS), fst, 'aa', max_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef756508-e3c8-4786-9b7d-2661add5ce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f44c5186-5bf0-411e-b4ac-341d73ea02b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(-3.912, {(0, 'abc')}, StatefulLM(['a', 'b', 'c']))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_sampling(StatefulLM(lm, EOS), fst, 'abc').sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b4b1ad8-9ea6-4d06-a1f5-4bdf2b2345c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(-1.386, {(0, 'aa')}, StatefulLM(['a', 'a']))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_sampling(StatefulLM(lm, EOS), fst, 'aa').sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53cc98-8e53-490b-b327-441533451dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}