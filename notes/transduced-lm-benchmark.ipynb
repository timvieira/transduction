{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db48063f-59c2-415e-8651-1a22b4e8c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d548702-ptb",
   "metadata": {},
   "source": [
    "# TransducedLM vs FusedTransducedLM Benchmark\n",
    "\n",
    "Compares two approaches to computing next-symbol log-probabilities through\n",
    "an FST on the Penn Treebank tokenizer (~296 states, 257 input symbols):\n",
    "\n",
    "- **TransducedLM**: two-phase (PeekabooState BFS decomposition, then LM-weighted search)\n",
    "- **FusedTransducedLM**: single-pass (interleaved decomposition + LM search, no separate BFS)\n",
    "\n",
    "Uses a 3-gram CharNgramLM as the inner LM, with per-call timeouts and a\n",
    "process-wide memory limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f45c1d-ptb",
   "metadata": {},
   "outputs": [],
   "source": "import signal, resource, time, gc\nimport numpy as np\n\n# ---- Safety: memory limit (8 GB virtual address space) ----\n_GB = 1024 ** 3\n_soft, _hard = resource.getrlimit(resource.RLIMIT_AS)\nresource.setrlimit(resource.RLIMIT_AS, (8 * _GB, _hard))\n\nclass _Timeout(Exception):\n    pass\n\ndef _alarm(signum, frame):\n    raise _Timeout()\n\ndef timed(fn, timeout_s=30, label=''):\n    \"\"\"Run fn() with wall-clock timeout. Returns (result, elapsed_s) or (None, None).\"\"\"\n    prev = signal.signal(signal.SIGALRM, _alarm)\n    signal.alarm(timeout_s)\n    try:\n        t0 = time.perf_counter()\n        out = fn()\n        return out, time.perf_counter() - t0\n    except _Timeout:\n        print(f'  {label} TIMEOUT ({timeout_s}s)')\n        return None, None\n    except MemoryError:\n        print(f'  {label} OOM')\n        return None, None\n    except Exception as e:\n        print(f'  {label} ERROR: {type(e).__name__}: {e}')\n        return None, None\n    finally:\n        signal.alarm(0)\n        signal.signal(signal.SIGALRM, prev)\n\n# ---- Remap multi-char PTB symbols to single Unicode chars ----\n# PeekabooPrecover NFA uses string concatenation for buffers and indexes by\n# character position, which breaks for multi-character symbol names like '84'.\ndef remap_fst_to_single_chars(fst):\n    from transduction.fst import FST as FSTClass\n    from transduction.fsa import EPSILON as _EPS\n    fwd, inv = {}, {}\n    code = 0xE000  # Unicode private-use area\n    for sym in sorted((fst.A | fst.B) - {_EPS}):\n        fwd[sym] = chr(code)\n        inv[chr(code)] = sym\n        code += 1\n    new_fst = FSTClass()\n    for s in fst.start: new_fst.add_start(s)\n    for s in fst.stop:  new_fst.add_stop(s)\n    for s in fst.states:\n        for x, y, j in fst.arcs(s):\n            new_x = fwd.get(x, x) if x != _EPS else _EPS\n            new_y = fwd.get(y, y) if y != _EPS else _EPS\n            new_fst.add_arc(s, new_x, new_y, j)\n    return new_fst, fwd, inv\n\n# ---- Build PTB FST (requires pynini) ----\nfrom transduction.applications.ptb import build_ptb_fst_pynini, string_to_byte_strs, decode_ptb_output\nfrom transduction.fst import FST\nfrom transduction.fsa import EPSILON\n\nt0 = time.perf_counter()\nraw_fst = build_ptb_fst_pynini()\nptb_fst, fwd_map, inv_map = remap_fst_to_single_chars(raw_fst)\nprint(f'PTB FST built in {time.perf_counter()-t0:.1f}s: '\n      f'{len(ptb_fst.states)} states, |A|={len(ptb_fst.A)}, |B|={len(ptb_fst.B)}')\n\n# Generate target sequence\ntext = \"The quick brown fox jumps over the lazy dog.\"\nbyte_strs = string_to_byte_strs(text)\nremapped_input = tuple(fwd_map[s] for s in byte_strs)\ninput_fst_obj = FST.from_string(remapped_input)\noutput_fsa = (input_fst_obj @ ptb_fst).project(1)\ntarget_seq = list(next(output_fsa.language()))\ndecoded = decode_ptb_output(tuple(inv_map.get(c, c) for c in target_seq))\nprint(f'Target: {len(target_seq)} symbols')\nprint(f'  {decoded!r}')\n\n# Train inner LM for TransducedLM benchmarks\nfrom transduction.lm.ngram import CharNgramLM\nsource_alpha = ptb_fst.A - {EPSILON}\ntrain_text = (\n    \"The quick brown fox jumps over the lazy dog. \"\n    \"A stitch in time saves nine. To be or not to be, that is the question. \"\n    \"All that glitters is not gold. Actions speak louder than words. \"\n    \"Practice makes perfect. Where there is a will, there is a way. \"\n) * 3\ntrain_syms = [fwd_map[s] for s in string_to_byte_strs(train_text)]\nfor sym in source_alpha:\n    train_syms.append(sym)\ninner_lm = CharNgramLM.train(train_syms, n=3, alpha=0.5)\nprint(f'Inner LM: alphabet={len(inner_lm.alphabet)} symbols')"
  },
  {
   "cell_type": "markdown",
   "id": "4445b584-ptb",
   "metadata": {},
   "source": [
    "## TransducedLM Scaling\n",
    "\n",
    "Per-step decode time for **TransducedLM** (two-phase: PeekabooState BFS\n",
    "decomposition, then LM-weighted search) vs **FusedTransducedLM** (single-pass:\n",
    "interleaved decomposition + LM search, no separate BFS).\n",
    "\n",
    "Each step includes both decomposition and LM search costs.  For TransducedLM,\n",
    "the PeekabooState BFS dominates (~35s per step on PTB).  FusedTransducedLM\n",
    "avoids the BFS entirely but builds the lazy DFA inline during search.\n",
    "\n",
    "Both use `max_steps=200`, `max_beam=100`, with a 120s timeout per step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b7551-ptb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TransducedLM (max_steps=200, max_beam=100):\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from transduction.lm.transduced import TransducedLM\n",
    "from transduction.lm.fused_transduced import FusedTransducedLM\n",
    "\n",
    "MAX_DECODE = 10              # number of decode steps\n",
    "MAX_SEARCH = 200             # max priority-queue steps per logp_next\n",
    "MAX_BEAM = 100               # max items carried forward\n",
    "LM_TIMEOUT = 120             # seconds per step\n",
    "\n",
    "# Expected runtime: ~15-20 min total (TransducedLM ~65s/step, FusedTransducedLM ~35s/step)\n",
    "\n",
    "lm_results = defaultdict(list)  # name -> [(step, time_s, logp)]\n",
    "\n",
    "for name, cls in [('TransducedLM', TransducedLM),\n",
    "                  ('FusedTransducedLM', FusedTransducedLM)]:\n",
    "    print(f'\\n{name} (max_steps={MAX_SEARCH}, max_beam={MAX_BEAM}):')\n",
    "    tlm = cls(inner_lm, ptb_fst, max_steps=MAX_SEARCH, max_beam=MAX_BEAM)\n",
    "    state = tlm.initial()\n",
    "    for i in range(min(MAX_DECODE, len(target_seq))):\n",
    "        y = target_seq[i]\n",
    "        def step(s=state, y=y):\n",
    "            lp = s.logp_next[y]\n",
    "            return s >> y, lp\n",
    "        out, t = timed(step, timeout_s=LM_TIMEOUT, label=f'step {i+1}')\n",
    "        if t is None:\n",
    "            break\n",
    "        state, lp = out\n",
    "        lm_results[name].append((i + 1, t, lp))\n",
    "        print(f'  {i+1:2d}: {t*1000:8.1f} ms  logp={lp:.4f}')\n",
    "    gc.collect()\n",
    "\n",
    "# Summary table\n",
    "print(f'\\n{\"Algorithm\":<25s} {\"Total (s)\":>10s} {\"Avg/step (s)\":>12s} {\"Steps\":>6s}')\n",
    "print('-' * 55)\n",
    "for name, data in sorted(lm_results.items()):\n",
    "    total = sum(t for _, t, _ in data)\n",
    "    avg = total / len(data)\n",
    "    print(f'{name:<25s} {total:10.1f} {avg:12.1f} {len(data):6d}')\n",
    "if len(lm_results) == 2:\n",
    "    names = sorted(lm_results.keys())\n",
    "    d0, d1 = lm_results[names[0]], lm_results[names[1]]\n",
    "    t0 = sum(t for _, t, _ in d0)\n",
    "    t1 = sum(t for _, t, _ in d1)\n",
    "    if t1 > 0:\n",
    "        print(f'\\nFused speedup (overall): {t0/t1:.2f}x')\n",
    "    # Exclude step 1 (amortization penalty for Fused)\n",
    "    if len(d0) > 1 and len(d1) > 1:\n",
    "        t0_skip1 = sum(t for _, t, _ in d0[1:])\n",
    "        t1_skip1 = sum(t for _, t, _ in d1[1:])\n",
    "        if t1_skip1 > 0:\n",
    "            print(f'Fused speedup (step 2+): {t0_skip1/t1_skip1:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b94e52-ptb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: time per step\n",
    "ax = axes[0]\n",
    "for name, data in sorted(lm_results.items()):\n",
    "    steps = [d[0] for d in data]\n",
    "    times = [d[1] for d in data]\n",
    "    ax.plot(steps, times, 'o-', label=name, markersize=4)\n",
    "ax.set_xlabel('Target step')\n",
    "ax.set_ylabel('Time per step (s)')\n",
    "ax.set_title(f'TransducedLM vs Fused (PTB, max_steps={MAX_SEARCH})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: per-step speedup\n",
    "ax = axes[1]\n",
    "if len(lm_results) == 2:\n",
    "    names = sorted(lm_results.keys())\n",
    "    d0, d1 = lm_results[names[0]], lm_results[names[1]]\n",
    "    n = min(len(d0), len(d1))\n",
    "    steps = [d0[i][0] for i in range(n)]\n",
    "    speedups = [d0[i][1] / d1[i][1] if d1[i][1] > 0 else 0 for i in range(n)]\n",
    "    colors = ['#2ecc71' if s > 1 else '#e74c3c' for s in speedups]\n",
    "    ax.bar(steps, speedups, color=colors, alpha=0.7, edgecolor='white')\n",
    "    ax.axhline(1.0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax.set_xlabel('Target step')\n",
    "    ax.set_ylabel('Speedup (Original / Fused)')\n",
    "    ax.set_title('Per-step speedup (>1 = Fused faster)')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    logp_diffs = [abs(d0[i][2] - d1[i][2]) for i in range(n)]\n",
    "    print(f'Max |logp| diff: {max(logp_diffs):.6f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa1351-ptb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore original memory limit\n",
    "resource.setrlimit(resource.RLIMIT_AS, (_soft, _hard))\n",
    "print('Memory limit restored.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d753a-74f5-4bd0-9c11-3aaef9f6c186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}