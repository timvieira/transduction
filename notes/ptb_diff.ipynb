{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pynini vs NLTK PTB Tokenizer — Adversarial Diff\n",
    "\n",
    "This notebook exercises known and remaining differences between the pynini FST\n",
    "and NLTK's `TreebankWordTokenizer`.\n",
    "\n",
    "**Fixed** (sections 1-5): `#` punctuation, ALL CAPS contractions, `d'ye`/`more'n`,\n",
    "`'tis`/`'twas`, `''` as opening quotes, closing-quote context (`\"B +\"`).\n",
    "\n",
    "**Remaining** (section 6): double contractions, `it's'`, `\"\"`, double comma/colon,\n",
    "tabs. None observed in 2000 wikitext paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from nltk.tokenize import TreebankWordTokenizer\nfrom transduction.applications.ptb import build_ptb_fst_pynini, decode_ptb_output\n\nnltk_tok = TreebankWordTokenizer()\nfst = build_ptb_fst_pynini()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def fst_tokenize(fst, text):\n    \"\"\"Tokenize text using the pynini-built FST.\"\"\"\n    try:\n        output = fst.transduce(text.encode('utf-8'))\n    except ValueError:\n        return None  # FST rejected input\n    return decode_ptb_output(output).split()\n\n\ndef compare(text):\n    \"\"\"Compare NLTK and FST tokenization, highlighting differences.\"\"\"\n    n = nltk_tok.tokenize(text)\n    f = fst_tokenize(fst, text)\n    match = '✓' if n == f else '✗'\n    print(f'{match} {text!r}')\n    if n != f:\n        print(f'  NLTK:  {n}')\n        print(f'  FST:   {f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `#` in special punctuation (FIXED)\n",
    "\n",
    "NLTK separates `[;@#$%&]`. Previously pynini only had `[;@%&$]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('Price is #100')\n",
    "compare('##heading')\n",
    "compare('C# programming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ALL CAPS contractions (FIXED, except arbitrary mixed case)\n",
    "\n",
    "NLTK's CONTRACTIONS2 uses `(?i)` (case-insensitive). Pynini now handles lowercase, Title, and UPPER.\n",
    "Arbitrary mixed case (e.g. `cAnNoT`) would require 2^n variants and is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('CANNOT STOP')\n",
    "compare('I WANNA GO')\n",
    "compare('GONNA BE GREAT')\n",
    "compare('GOTTA RUN')\n",
    "compare('LEMME SEE')\n",
    "compare('GIMME THAT')\n",
    "compare('cAnNoT stop')  # mixed case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `d'ye`, `more'n` contractions (FIXED)\n",
    "\n",
    "Added to pynini's contraction list with lowercase/Title/UPPER variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(\"D'ye think so?\")\n",
    "compare(\"d'ye know\")\n",
    "compare(\"more'n enough\")\n",
    "compare(\"More'n I expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `'tis`, `'twas` — CONTRACTIONS3 (FIXED)\n",
    "\n",
    "Added as a separate contraction stage in the pynini pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(\"'Tis the season\")\n",
    "compare(\"'Twas the night\")\n",
    "compare(\"'tis nothing\")\n",
    "compare(\"'twas long ago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Double single-quotes `''` as opening quote (FIXED)\n",
    "\n",
    "NLTK STARTING_QUOTES rule 3 converts `''` after space/brackets to `` `` ``.\n",
    "Also fixed: remaining `\"` now correctly becomes `''` (not `` `` ``) matching NLTK's ENDING_QUOTES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(\"She said ''hello'' there\")\n",
    "compare(\"''Hello,'' she replied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Remaining exotic differences\n",
    "\n",
    "These are real differences that we accept. None appear in 2000 wikitext paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double contraction: NLTK keeps wouldn't as a unit, then splits 've.\n",
    "# Pynini splits n't first (both valid decompositions, different order).\n",
    "compare(\"wouldn't've\")\n",
    "\n",
    "# Clitic + trailing apostrophe: NLTK keeps it's together.\n",
    "# Pynini splits 's first, leaving a bare trailing '.\n",
    "compare(\"it's'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two adjacent double quotes: NLTK makes both ``, pynini makes first `` second ''\n",
    "# (NLTK: ^\" fires, then remaining \" -> '' but wait, ^\" only matches first char...\n",
    "#  actually NLTK does ^\" -> `` then \" -> '' in ENDING_QUOTES, but the first \"\n",
    "#  at BOS becomes `` and the second \" also matches ^\" context... tricky!)\n",
    "compare('\"\"')\n",
    "\n",
    "# Double comma: NLTK regex ([:,])([^\\d]) consumes the second , as the\n",
    "# non-digit lookahead, so only the first comma is separated.\n",
    "compare(\"a,,b\")\n",
    "\n",
    "# Double colon: same regex interaction as double comma.\n",
    "compare(\"::colon\")\n",
    "\n",
    "# Tab: NLTK's .split() treats tabs as whitespace. Pynini only maps space to separator.\n",
    "compare(\"hello\\tworld\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sanity checks (should all match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(\"I can't do it.\")\n",
    "compare(\"It's a test -- really!\")\n",
    "compare(\"Don't you think?\")\n",
    "compare(\"I'll go there.\")\n",
    "compare(\"We've been here.\")\n",
    "compare('1,000 people')\n",
    "compare('at 3:00 PM')\n",
    "compare('items: none')\n",
    "compare('foo;bar')\n",
    "compare('$100 & more')\n",
    "compare('50% off @ store')\n",
    "compare('\"Hello,\" she said.')\n",
    "compare('He said, \"go!\"')\n",
    "compare('\"a\"')\n",
    "compare('She said \"don\\'t\"')\n",
    "compare('Hello world. Goodbye.')\n",
    "compare('a.')\n",
    "compare(\"the kids' toys\")\n",
    "compare(\"James' book\")\n",
    "compare(\"CAN'T STOP WON'T STOP\")\n",
    "compare('a \"B +\" grade on average.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Wikitext bulk comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.applications.wikitext import load_wikitext, wikitext_detokenize\n",
    "\n",
    "dataset = load_wikitext(\"test\")\n",
    "n_tested = n_match = n_error = 0\n",
    "diffs = []\n",
    "\n",
    "for item in dataset:\n",
    "    text = item[\"text\"].strip()\n",
    "    if not text or text.startswith(\"=\"):\n",
    "        continue\n",
    "    text = wikitext_detokenize(text)[:500]\n",
    "    if len(text) < 10:\n",
    "        continue\n",
    "\n",
    "    n = nltk_tok.tokenize(text)\n",
    "    f = fst_tokenize(fst, text)\n",
    "    n_tested += 1\n",
    "\n",
    "    if f is None:\n",
    "        n_error += 1\n",
    "    elif n == f:\n",
    "        n_match += 1\n",
    "    else:\n",
    "        for i in range(max(len(n), len(f))):\n",
    "            nt = n[i] if i < len(n) else \"<END>\"\n",
    "            ft = f[i] if i < len(f) else \"<END>\"\n",
    "            if nt != ft:\n",
    "                diffs.append((n_tested, text[:80], nt, ft))\n",
    "                break\n",
    "\n",
    "    if n_tested >= 2000:\n",
    "        break\n",
    "\n",
    "print(f\"Tested:  {n_tested}\")\n",
    "print(f\"Match:   {n_match} ({100*n_match/n_tested:.1f}%)\")\n",
    "print(f\"Errors:  {n_error}\")\n",
    "print(f\"Diffs:   {len(diffs)}\")\n",
    "for idx, txt, nt, ft in diffs[:10]:\n",
    "    print(f\"  #{idx}: NLTK={nt!r} FST={ft!r}  text={txt!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}