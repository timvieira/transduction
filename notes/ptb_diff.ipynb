{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pynini vs NLTK PTB Tokenizer — Adversarial Diff\n",
    "\n",
    "This notebook exercises known and remaining differences between the pynini FST\n",
    "and NLTK's `TreebankWordTokenizer`.\n",
    "\n",
    "**Fixed** (sections 1-5): `#` punctuation, ALL CAPS contractions, `d'ye`/`more'n`,\n",
    "`'tis`/`'twas`, `''` as opening quotes, closing-quote context (`\"B +\"`).\n",
    "\n",
    "**Remaining** (section 6): double contractions, `it's'`, `\"\"`, double comma/colon,\n",
    "tabs. None observed in 2000 wikitext paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys; sys.path.insert(0, '..')\n\nfrom nltk.tokenize import TreebankWordTokenizer\nfrom transduction.applications.ptb import build_ptb_fst_pynini, string_to_byte_strs, SEP\nfrom transduction.fsa import EPSILON as NATIVE_EPSILON\n\nnltk_tok = TreebankWordTokenizer()\nfst = build_ptb_fst_pynini()"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transduction.fst import FST\n",
    "\n",
    "\n",
    "def fst_tokenize(fst, text):\n",
    "    \"\"\"Tokenize text using the pynini-built FST.\"\"\"\n",
    "    byte_strs = string_to_byte_strs(text)\n",
    "    input_fst = FST.from_string(byte_strs)\n",
    "    output_fsa = fst(input_fst, None)\n",
    "    try:\n",
    "        output = next(output_fsa.language(tuple=True))\n",
    "    except StopIteration:\n",
    "        return None  # FST rejected input\n",
    "    tokens = []\n",
    "    current = []\n",
    "    for sym in output:\n",
    "        if sym == SEP:\n",
    "            if current:\n",
    "                tokens.append(bytes(int(b) for b in current).decode('utf-8', errors='replace'))\n",
    "                current = []\n",
    "        elif int(sym) < 256:\n",
    "            current.append(sym)\n",
    "    if current:\n",
    "        tokens.append(bytes(int(b) for b in current).decode('utf-8', errors='replace'))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def compare(text):\n",
    "    \"\"\"Compare NLTK and FST tokenization, highlighting differences.\"\"\"\n",
    "    n = nltk_tok.tokenize(text)\n",
    "    f = fst_tokenize(fst, text)\n",
    "    match = '✓' if n == f else '✗'\n",
    "    print(f'{match} {text!r}')\n",
    "    if n != f:\n",
    "        print(f'  NLTK:  {n}')\n",
    "        print(f'  FST:   {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `#` in special punctuation (FIXED)\n",
    "\n",
    "NLTK separates `[;@#$%&]`. Previously pynini only had `[;@%&$]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 'Price is #100'\n",
      "✓ '##heading'\n",
      "✓ 'C# programming'\n"
     ]
    }
   ],
   "source": [
    "compare('Price is #100')\n",
    "compare('##heading')\n",
    "compare('C# programming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ALL CAPS contractions (FIXED, except arbitrary mixed case)\n",
    "\n",
    "NLTK's CONTRACTIONS2 uses `(?i)` (case-insensitive). Pynini now handles lowercase, Title, and UPPER.\n",
    "Arbitrary mixed case (e.g. `cAnNoT`) would require 2^n variants and is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 'CANNOT STOP'\n",
      "✓ 'I WANNA GO'\n",
      "✓ 'GONNA BE GREAT'\n",
      "✓ 'GOTTA RUN'\n",
      "✓ 'LEMME SEE'\n",
      "✓ 'GIMME THAT'\n",
      "✗ 'cAnNoT stop'\n",
      "  NLTK:  ['cAn', 'NoT', 'stop']\n",
      "  FST:   ['cAnNoT', 'stop']\n"
     ]
    }
   ],
   "source": [
    "compare('CANNOT STOP')\n",
    "compare('I WANNA GO')\n",
    "compare('GONNA BE GREAT')\n",
    "compare('GOTTA RUN')\n",
    "compare('LEMME SEE')\n",
    "compare('GIMME THAT')\n",
    "compare('cAnNoT stop')  # mixed case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `d'ye`, `more'n` contractions (FIXED)\n",
    "\n",
    "Added to pynini's contraction list with lowercase/Title/UPPER variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"D'ye think so?\"\n",
      "✓ \"d'ye know\"\n",
      "✓ \"more'n enough\"\n",
      "✓ \"More'n I expected\"\n"
     ]
    }
   ],
   "source": [
    "compare(\"D'ye think so?\")\n",
    "compare(\"d'ye know\")\n",
    "compare(\"more'n enough\")\n",
    "compare(\"More'n I expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `'tis`, `'twas` — CONTRACTIONS3 (FIXED)\n",
    "\n",
    "Added as a separate contraction stage in the pynini pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"'Tis the season\"\n",
      "✓ \"'Twas the night\"\n",
      "✓ \"'tis nothing\"\n",
      "✓ \"'twas long ago\"\n"
     ]
    }
   ],
   "source": [
    "compare(\"'Tis the season\")\n",
    "compare(\"'Twas the night\")\n",
    "compare(\"'tis nothing\")\n",
    "compare(\"'twas long ago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Double single-quotes `''` as opening quote (FIXED)\n",
    "\n",
    "NLTK STARTING_QUOTES rule 3 converts `''` after space/brackets to `` `` ``.\n",
    "Also fixed: remaining `\"` now correctly becomes `''` (not `` `` ``) matching NLTK's ENDING_QUOTES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"She said ''hello'' there\"\n",
      "✓ \"''Hello,'' she replied\"\n"
     ]
    }
   ],
   "source": [
    "compare(\"She said ''hello'' there\")\n",
    "compare(\"''Hello,'' she replied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Remaining exotic differences\n",
    "\n",
    "These are real differences that we accept. None appear in 2000 wikitext paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ \"wouldn't've\"\n",
      "  NLTK:  [\"wouldn't\", \"'ve\"]\n",
      "  FST:   ['would', \"n't\", \"'ve\"]\n",
      "✗ \"it's'\"\n",
      "  NLTK:  [\"it's\", \"'\"]\n",
      "  FST:   ['it', \"'s\", \"'\"]\n"
     ]
    }
   ],
   "source": [
    "# Double contraction: NLTK keeps wouldn't as a unit, then splits 've.\n",
    "# Pynini splits n't first (both valid decompositions, different order).\n",
    "compare(\"wouldn't've\")\n",
    "\n",
    "# Clitic + trailing apostrophe: NLTK keeps it's together.\n",
    "# Pynini splits 's first, leaving a bare trailing '.\n",
    "compare(\"it's'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ '\"\"'\n",
      "  NLTK:  ['``', '``']\n",
      "  FST:   ['``', \"''\"]\n",
      "✗ 'a,,b'\n",
      "  NLTK:  ['a', ',', ',b']\n",
      "  FST:   ['a', ',', ',', 'b']\n",
      "✗ '::colon'\n",
      "  NLTK:  [':', ':colon']\n",
      "  FST:   [':', ':', 'colon']\n",
      "✗ 'hello\\tworld'\n",
      "  NLTK:  ['hello', 'world']\n",
      "  FST:   ['hello\\tworld']\n"
     ]
    }
   ],
   "source": [
    "# Two adjacent double quotes: NLTK makes both ``, pynini makes first `` second ''\n",
    "# (NLTK: ^\" fires, then remaining \" -> '' but wait, ^\" only matches first char...\n",
    "#  actually NLTK does ^\" -> `` then \" -> '' in ENDING_QUOTES, but the first \"\n",
    "#  at BOS becomes `` and the second \" also matches ^\" context... tricky!)\n",
    "compare('\"\"')\n",
    "\n",
    "# Double comma: NLTK regex ([:,])([^\\d]) consumes the second , as the\n",
    "# non-digit lookahead, so only the first comma is separated.\n",
    "compare(\"a,,b\")\n",
    "\n",
    "# Double colon: same regex interaction as double comma.\n",
    "compare(\"::colon\")\n",
    "\n",
    "# Tab: NLTK's .split() treats tabs as whitespace. Pynini only maps space to separator.\n",
    "compare(\"hello\\tworld\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sanity checks (should all match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ \"I can't do it.\"\n",
      "✓ \"It's a test -- really!\"\n",
      "✓ \"Don't you think?\"\n",
      "✓ \"I'll go there.\"\n",
      "✓ \"We've been here.\"\n",
      "✓ '1,000 people'\n",
      "✓ 'at 3:00 PM'\n",
      "✓ 'items: none'\n",
      "✓ 'foo;bar'\n",
      "✓ '$100 & more'\n",
      "✓ '50% off @ store'\n",
      "✓ '\"Hello,\" she said.'\n",
      "✓ 'He said, \"go!\"'\n",
      "✓ '\"a\"'\n",
      "✓ 'She said \"don\\'t\"'\n",
      "✓ 'Hello world. Goodbye.'\n",
      "✓ 'a.'\n",
      "✓ \"the kids' toys\"\n",
      "✓ \"James' book\"\n",
      "✓ \"CAN'T STOP WON'T STOP\"\n",
      "✓ 'a \"B +\" grade on average.'\n"
     ]
    }
   ],
   "source": [
    "compare(\"I can't do it.\")\n",
    "compare(\"It's a test -- really!\")\n",
    "compare(\"Don't you think?\")\n",
    "compare(\"I'll go there.\")\n",
    "compare(\"We've been here.\")\n",
    "compare('1,000 people')\n",
    "compare('at 3:00 PM')\n",
    "compare('items: none')\n",
    "compare('foo;bar')\n",
    "compare('$100 & more')\n",
    "compare('50% off @ store')\n",
    "compare('\"Hello,\" she said.')\n",
    "compare('He said, \"go!\"')\n",
    "compare('\"a\"')\n",
    "compare('She said \"don\\'t\"')\n",
    "compare('Hello world. Goodbye.')\n",
    "compare('a.')\n",
    "compare(\"the kids' toys\")\n",
    "compare(\"James' book\")\n",
    "compare(\"CAN'T STOP WON'T STOP\")\n",
    "compare('a \"B +\" grade on average.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Wikitext bulk comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from benchmark.data import load_wikitext, wikitext_detokenize\n\ndataset = load_wikitext(\"test\")\nn_tested = n_match = n_error = 0\ndiffs = []\n\nfor item in dataset:\n    text = item[\"text\"].strip()\n    if not text or text.startswith(\"=\"):\n        continue\n    text = wikitext_detokenize(text)[:500]\n    if len(text) < 10:\n        continue\n\n    n = nltk_tok.tokenize(text)\n    f = fst_tokenize(fst, text)\n    n_tested += 1\n\n    if f is None:\n        n_error += 1\n    elif n == f:\n        n_match += 1\n    else:\n        for i in range(max(len(n), len(f))):\n            nt = n[i] if i < len(n) else \"<END>\"\n            ft = f[i] if i < len(f) else \"<END>\"\n            if nt != ft:\n                diffs.append((n_tested, text[:80], nt, ft))\n                break\n\n    if n_tested >= 2000:\n        break\n\nprint(f\"Tested:  {n_tested}\")\nprint(f\"Match:   {n_match} ({100*n_match/n_tested:.1f}%)\")\nprint(f\"Errors:  {n_error}\")\nprint(f\"Diffs:   {len(diffs)}\")\nfor idx, txt, nt, ft in diffs[:10]:\n    print(f\"  #{idx}: NLTK={nt!r} FST={ft!r}  text={txt!r}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}